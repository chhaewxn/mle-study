# 우리가 공부한 것 🙇

## CHAPTER 3. 데이터 엔지니어링 기초

> **ML 시스템의 성능은 데이터의 품질과 구조에 달려있다.**
> 

---

### 3.1 데이터 소스

데이터 소스는 크게 **사용자 입력 데이터**와 **시스템 생성 데이터**로 나뉨

| 구분 | 사용자 입력 데이터 | 시스템 생성 데이터 |
| --- | --- | --- |
| **정의** | 사용자가 명시적으로 입력하는 데이터 | 시스템 구성 요소에서 자동 생성되는 데이터 |
| **예시** | 유저가 입력하는 모든 데이터 | 로그, 모델 예측 출력 등 |
| **포맷 오류 가능성** | 높음 (길이, 타입 오류 등) - Human Error | 낮음 |
| **처리 시점** | 즉시 처리 필요 (사용자가 기다림) | 주기적 처리 가능 (매시간/매일) |
| **핵심 요구사항** | 1. 엄격한 Validation check<br>2. 빠른 처리 | 1. 가시성 확보<br>2. 디버깅/개선용 |
| **주요 용도** | 서비스 기능 제공 | 시스템 상태 모니터링, 이상 감지 |

**로그 관리의 문제점과 해결책**

- ML 시스템은 일반적으로 모든 로그를 남김 (디버깅하기 어려워서)
- 문제점 1: **가독성 저하** → 로그스태시, 데이터독, Logz.io 등의 서비스가 방대한 로그 처리 및 분석 지원
- 문제점 2: **거대한 스토리지 요구** → 로그에 자주 액세스하지 않는다면 낮은 액세스 스토리지에 저장하여 비용 절감 가능

**데이터 수집 환경의 변화**

- **과거**: 스마트폰마다 고유 광고 ID 존재
    - 아이폰: IDFA(Identifier for Advertisers)
    - 안드로이드: AAID(Android Advertising ID)
    - 모든 활동을 집계하는 고유 ID 역할
- **현재**: 고유 광고 ID 사용을 제한
    - 2021년 초 애플: 기존 IDFA 수집 방식을 Opt-in(옵트인)으로 변경
    - 이유: 사용자의 더 높은 데이터 프라이버시 요구

---

### 3.2 데이터 포맷

### 3.2.1 JSON

**JSON(JavaScript Object Notation)**

```json
{
  "firstName": "Boatie",
  "lastName": "McBoatFace",
  "isVibing": true,
  "age": 12,
  "address": {
    "streetAddress": "12 Ocean Drive",
    "city": "Port Royal",
    "postalCode": "10021-3100"
  }
}

```

**장점**

- 최신 프로그래밍 언어 대부분이 JSON 생성, 파싱을 지원
- 사람이 읽을 수 있음
- Key-value 쌍 패러다임으로 이뤄짐

**단점**

- 스키마에 커밋한 후 스키마를 변경하기 위해 다시 되돌아가는 것이 매우 번거로움
- 많은 저장 공간 차지 (텍스트 파일이므로)

### 3.2.2 행 우선 포맷 vs 열 우선 포맷

| 구분 | 행 우선 포맷 (CSV) | 열 우선 포맷 (Parquet) |
| --- | --- | --- |
| **메모리 저장 방식** | 행 단위로 연속 저장 | 열 단위로 연속 저장 |
| **장점** | - 더 빠른 데이터 쓰기<br>- 샘플(행)에 액세스하기 좋음 | - 유연한 열 기반 읽기 (피처 수 많을 때 유용)<br>- 피처(열)에 액세스하기 좋음 |
| **예시 포맷** | CSV | Parquet |
| **읽기 성능** | 행 기준 읽기 빠름 | 열 기준 읽기 빠름 |
| **쓰기 성능** | 빠름 | 상대적으로 느림 |

### 3.2.3 텍스트 포맷 vs 이진 포맷

**이진 파일이란?**

1. 텍스트가 아닌 모든 파일을 지칭하는 표현
2. 0과 1만을 포함하며, 원시 바이트를 해석하는 방법을 알고 있는 프로그램에서 읽거나 사용하기 위한 파일
3. 프로그램은 이진 파일 내부 데이터가 **어떻게 배치돼 있는지 정확히 알아야** 파일 사용 가능

| 구분 | 텍스트 포맷 | 이진 포맷 |
| --- | --- | --- |
| **사람이 읽기** | 쉽다 | 어렵다 (툴 필요) |
| **타입/정밀도** | 부정확, 손실 위험 있음 | 타입, 정밀도 보존 |
| **용량** | 큼 | 작음 → 공간 절약 |
| **예시** | CSV, JSON | Parquet (AWS가 사랑하는 포맷) |

---

### 3.3 데이터 모델

데이터 모델 = 데이터가 어떻게 표현되는지 설명 → **시스템 구축 방식**, **시스템이 해결하려는 문제**에 영향

**예시**: 자동차 데이터 모델을 만들 때

- 모델 A: 제조사, 모델명, 연도, 색, 가격 → 자동차 구매자에게 도움
- 모델 B: 소유자, 번호판, 등록 주소 기록 → 경찰관이 범죄자 추적 시 도움

### 3.3.1 관계형 모델

**데이터 저장**

- 데이터를 테이블(행과 열) 형태로 표현하는 방식
- 가장 중요한 특징: **행과 열의 순서가 의미가 없음**. 관계는 순서가 없음
- **정규화(Normalization)**: 중복을 줄이고 데이터 무결성을 높이는 절차
    - 예: 책 데이터를 저장할 때 출판사 정보를 별도 테이블로 분리하여 한 곳만 수정하면 되도록 함
    - 주요 단점: 데이터가 여러 관계로 분산됨. 조인 시 연산 비용 증가 가능

**데이터 조회**

- 원하는 데이터를 지정하는 데 사용하는 쿼리 언어 사용
- 대표적으로 **SQL**: 관계형 모델을 바탕으로 만들어진 **선언적 쿼리 언어**
    - 엄밀히 관계형 모델과 100% 일치하진 않지만, 큰 문제는 아니라 많이 무시함

| 구분 | 파이썬 | SQL |
| --- | --- | --- |
| **특성** | 명령형 언어 | 선언적 언어 |
| **의미** | 어떤 순서로 무엇을 할지 적어줘야 함 | 어떤 결과가 필요하다만 적음. 어떻게 실행할지는 DB가 알아서 결정 |

**선언적 ML 시스템**

- 선언적 언어에서 영감을 얻어 모델 개발 부분을 **추상화**해주는 역할
- 하고 싶은 ML 작업을 선언하면 어떤 모델을 쓰고, 어떻게 학습할지는 시스템이 결정

### 3.3.2 NoSQL

**관계형 데이터베이스의 한계**

관계형 DB는 널리 쓰이지만 몇 가지 문제가 있음:

- **스키마 관리가 어려움**: 데이터가 엄격한 스키마를 따라야 하고, 스키마 변경 시 모든 데이터 업데이트 필요
- **특화된 쿼리 작성이 복잡함**: 복잡한 애플리케이션에서 SQL 쿼리 작성/실행이 어려움

**NoSQL이란?**

**NoSQL = Not Only SQL**: 비관계형 데이터베이스를 포함하되, 관계형 모델도 지원하는 시스템

**(1) 문서 모델**: 데이터가 독립적인 문서로 제공되고, 문서 간 관계가 드문 경우

**(2) 그래프 모델**: 데이터 항목 간 관계가 흔하고 중요한 경우

**(1) 문서 모델 (Document Model)**

**핵심 개념**: 데이터를 '문서' 단위로 저장 (JSON, XML, BSON 형식)

- 각 문서는 고유한 키를 가지고, 문서 컬렉션 ≒ 관계형 DB의 테이블
- **스키마리스**: 같은 컬렉션 내 문서들도 서로 다른 구조 가능

**장점: 지역성(Locality)이 우수함**

- 관계형 DB: 책 정보가 여러 테이블에 분산 → 여러 테이블 쿼리 필요
- 문서 모델: 책 정보를 하나의 문서에 몰아넣음 → 검색이 훨씬 간단

```json
// 예시: 해리_포터.json
{
  "제목": "해리 포터",
  "작가": "J. K. 롤링",
  "출판사": "바나나 출판",
  "출판 국가": "UK",
  "판매 정보": [
    {"포맷": "종이책", "가격": "$20"},
    {"포맷": "전자책", "가격": "$10"}
  ]
}

```

**단점: 문서 간 조인이 어렵고 비효율적임**

- 예: "가격이 25달러 미만인 책 찾기" → 모든 문서 읽고, 가격 추출하고, 비교 필요
- 관계형 DB에서는 간단한 WHERE 절로 해결되는 쿼리가 복잡해짐

→ **실무에서는 PostgreSQL, MySQL 같은 DB가 관계형 + 문서 모델 둘 다 지원**

**(2) 그래프 모델 (Graph Model)**

**핵심 개념**: 노드(Node)와 엣지(Edge)로 구성된 그래프로 데이터 저장

- 문서 DB는 "문서 내용"이 우선이라면, 그래프 DB는 "데이터 간 관계"가 우선
- 관계를 명시적으로 모델링하므로 **관계 기반 검색이 빠름**

**예시: 소셜 네트워크**

- 노드: 사람(Person), 도시(City), 국가(Country), 주(State)
- 엣지: born_in, within, friends_with 등

**그래프 모델이 강력한 경우**:

- "미국에서 태어난 사람 모두 찾기"
    - 그래프: USA 노드 → within 엣지 → born_in 엣지 따라가면 끝
    - 관계형/문서: 홉(연결 횟수)을 모르면 쿼리 작성 불가능
        - 예: Zhenzhong Xu와 USA = 3홉, Chloe He와 USA = 2홉

→ **데이터 모델마다 쉬운 쿼리/어려운 쿼리가 다름. 애플리케이션에 맞는 모델 선택이 핵심**

**데이터 모델 비교 요약**

| 항목 | 관계형 DB | 문서 DB | 그래프 DB |
| --- | --- | --- | --- |
| **데이터 단위** | 테이블 + 행 | 문서 컬렉션 | 노드 + 엣지 |
| **스키마** | 엄격함 | 유연함 | 유연함 |
| **강점** | 조인, 트랜잭션 | 지역성, 유연성 | 관계 탐색 |
| **약점** | 스키마 변경 어려움 | 조인 비효율적 | 단순 집계 느림 |
| **적합한 경우** | 트랜잭션 많은 시스템 | 독립적 문서 저장 | 소셜 네트워크, 추천 |

### 3.3.3 정형 데이터 vs 비정형 데이터

**정형 데이터 (Structured Data)**

**정의**: 미리 정의된 스키마를 따르는 데이터

- 예: `name`(최대 50자 문자열), `age`(0~200 사이 8비트 정수)

**장점**:

- 분석이 쉬움 (예: 평균 연령 계산 → 모든 age 값 추출해서 평균 내면 끝)

**단점**:

- **스키마 변경 시 모든 데이터를 소급 업데이트해야 함**
    - 예: 이전에는 이메일 보관 안 했는데 지금은 보관 → 기존 사용자 이메일 전부 업데이트 필요
    - 버그 예시: null 연령을 0으로 대체했더니 ML 모델이 "0세가 거래함"으로 인식
- 비즈니스 요구사항이 바뀌면 스키마 종속성 때문에 제약 많음

**비정형 데이터 (Unstructured Data)**

**정의**: 미리 정의된 스키마를 따르지 않는 데이터 (텍스트, 이미지, 오디오 등)

- 예: ML 모델 로그 텍스트 파일

**특징**:

- 스키마는 없지만 **고유한 패턴**은 있을 수 있음

```
Lisa, 43
Jack, 23
Huyen, 59
```

(쉼표로 구분된 이름, 나이 패턴 보임. 근데 모든 행이 이걸 따라야 한다는 보장은 없음)

**장점**:

- **유연한 스토리지**: 스키마에 얽매이지 않고 어떤 유형이든 저장 가능
- 모든 데이터를 바이트스트링으로 변환해 함께 저장 가능

**데이터 웨어하우스 vs 데이터 레이크**

| 구분 | 정형 데이터 | 비정형 데이터 |
| --- | --- | --- |
| **저장소 이름** | 데이터 웨어하우스 (Data Warehouse) | 데이터 레이크 (Data Lake) |
| **용도** | 처리된 데이터를 사용 가능한 형식으로 저장 | 처리 전 원시 데이터 저장 |
| **스키마** | 필수 | 선택 |
| **분석 용이성** | 높음 (구조화됨) | 낮음 (후처리 필요) |
| **유연성** | 낮음 (스키마 변경 어려움) | 높음 (어떤 형식이든 저장 가능) |

**정리하면**

- **NoSQL은 관계형 DB의 스키마 경직성 문제를 해결하려고 나옴** → 문서 모델(독립적 데이터), 그래프 모델(관계 중심 데이터)로 나뉨
- **문서 모델은 지역성이 좋지만 조인이 약함** → 한 문서에 정보 다 넣으면 검색은 빠른데, 문서 간 연결 쿼리는 비효율적
- **그래프 모델은 관계 탐색에 최적화됨** → 홉 수를 모르는 복잡한 관계 쿼리도 그래프 탐색으로 간단히 해결
- **정형 데이터는 분석 쉽지만 유연성 떨어짐** → 스키마 변경 시 모든 데이터 소급 업데이트, 버그 위험 큼
- **비정형 데이터는 유연하지만 후처리 필요** → 어떤 형식이든 저장 가능하지만, 분석하려면 구조 추출 과정 필요

→ **결론: 쿼리 패턴과 데이터 특성에 따라 적합한 모델/저장소 선택해야 함**

---

## 질문모음.zip 🤔

**Q1. First Party Data, Second Party Data, Third Party Data의 구체적인 차이는?**

A. First Party Data는 회사에서 직접 수집한 자사 고객 데이터, Second Party Data는 다른 회사의 First Party Data를 구매하여 얻은 데이터, Third Party Data는 공공 데이터 등 직접적인 고객이 아닌 대상에서 수집한 데이터를 의미합니다.

**Q2. 스키마에 커밋한 후 스키마 변경하기 위해 돌아가는 일이 상당히 번거롭다는 의미가 무슨 뜻?**

A. 한 번 스키마(데이터 구조)를 정해놓고 시스템에 넣어두면 나중에 바꾸기가 힘들다는 의미입니다. 스키마를 변경하려면 기존 데이터 구조를 모두 업데이트해야 하고, 이미 작성된 코드나 쿼리도 함께 수정해야 하는 번거로움이 있습니다.

**Q3. 문서 모델에서 "스키마리스"라고 하지만 읽는 쪽에서 구조를 가정한다는 게, 결국 암묵적 스키마가 있다는 건데 관계형 DB의 명시적 스키마와 비교해서 실무에서 어느 쪽이 더 유지보수하기 편한가?**

A. 장기적인 유지보수는 명시적 스키마(RDBMS)가 훨씬 편합니다. 스키마리스는 초기 개발 속도는 빠르지만, 시간이 지나면 여러 버전의 데이터가 뒤섞이고 방어적 코딩이 필요해 코드 복잡도가 증가합니다. 명시적 스키마는 초기 고통이 있지만, DB의 데이터 형태가 보장되어 장기적으로 안정적입니다. 실무에서는 메인 트랜잭션 데이터는 RDBMS로, 로그성 데이터나 자주 바뀌는 메타데이터는 JSON/NoSQL로 관리하는 하이브리드 방식을 선호합니다.

**Q4. 데이터 레이크에 원시 데이터 쌓아두면 나중에 스키마 추출할 때 비용이 어마어마할 텐데, 실무에서는 어느 정도까지 "일단 다 넣고 나중에 처리"하는 전략을 쓰나?**

A. "나중에 처리"는 "나중에 쿼리 날릴 때 처리"가 아니라, "나중에 배치 잡으로 구조화된 테이블을 만들어 두겠다"는 뜻이어야 합니다. 실무에서는 Bronze Layer(원시 데이터 그대로 저장) → Silver/Gold Layer(정형화된 포맷으로 변환)의 2-Tier 전략을 주로 사용합니다. 저장(Storage)은 스키마리스로 하되, 활용(Compute)은 반드시 스키마를 입혀서 사용합니다. Raw JSON에 직접 쿼리를 날리는 것은 비용 청구서를 보고 후회하게 됩니다.

**Q5. 그래프 DB에서 홉 수가 늘어나면 (예: 5홉, 10홉) 성능이 어떻게 변하는지, 실무에서는 몇 홉까지가 현실적인 쿼리 범위인가?**

A. 홉 수가 늘어날수록 탐색해야 할 노드와 엣지가 기하급수적으로 증가하여 성능이 저하될 수 있습니다. 실무에서는 일반적으로 2-3홉 정도가 현실적인 쿼리 범위로 알려져 있으나, 그래프 DB의 최적화 정도와 데이터 구조에 따라 달라질 수 있습니다.

---